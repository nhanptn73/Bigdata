{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jia0pO662Y8m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Embedding,LSTM,Dropout,Dense,Layer\n",
        "from keras import Model,Input\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "import collections\n",
        "import numpy as np\n",
        "import time\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQWdYrjZ3hvN"
      },
      "outputs": [],
      "source": [
        "class LanguageDict():\n",
        "  def __init__(self, sents):\n",
        "    word_counter = collections.Counter(tok.lower() for sent in sents for tok in sent)\n",
        "\n",
        "    self.vocab = []\n",
        "    self.vocab.append('<pad>')\n",
        "    self.vocab.append('<unk>')\n",
        "    self.vocab.extend([t for t,c in word_counter.items() if c > 10])\n",
        "\n",
        "    self.word2ids = {w:id for id, w in enumerate(self.vocab)}\n",
        "    self.ids2word = dict([(value, key) for (key, value) in self.word2ids.items()])\n",
        "    self.UNK = self.word2ids['<unk>']\n",
        "    self.PAD = self.word2ids['<pad>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI7yHurq3h3X"
      },
      "outputs": [],
      "source": [
        "def load_dataset(source_path,target_path, max_num_examples=10000):\n",
        "  source_lines = open(source_path).readlines()\n",
        "  target_lines = open(target_path).readlines()\n",
        "  assert len(source_lines) == len(target_lines)\n",
        "  if max_num_examples > 0:\n",
        "    max_num_examples = min(len(source_lines), max_num_examples)\n",
        "    source_lines = source_lines[:max_num_examples]\n",
        "    target_lines = target_lines[:max_num_examples]\n",
        "\n",
        "  source_sents = [[tok.lower() for tok in sent.strip().split(' ')] for sent in source_lines]\n",
        "  target_sents = [[tok.lower() for tok in sent.strip().split(' ')] for sent in target_lines]\n",
        "\n",
        "  for sent in target_sents:\n",
        "    sent.append('<end>')\n",
        "    sent.insert(0,'<start>')\n",
        "\n",
        "  source_lang_dict = LanguageDict(source_sents)\n",
        "  target_lang_dict = LanguageDict(target_sents)\n",
        "\n",
        "  unit = len(source_sents)//10\n",
        "  source_words = [[source_lang_dict.word2ids.get(tok,source_lang_dict.UNK) for tok in sent] for sent in source_sents]\n",
        "  source_words_train = pad_sequences(source_words[:8*unit],padding='post')\n",
        "  source_words_dev = pad_sequences(source_words[8*unit:9*unit],padding='post')\n",
        "  source_words_test = pad_sequences(source_words[9*unit:],padding='post')\n",
        "\n",
        "\n",
        "  eos = target_lang_dict.word2ids['<end>']\n",
        "  target_words = [[target_lang_dict.word2ids.get(tok,target_lang_dict.UNK) for tok in sent[:-1]] for sent in target_sents]\n",
        "  target_words_train = pad_sequences(target_words[:8*unit],padding='post')\n",
        "  target_words_train_labels = [sent[1:]+[eos] for sent in target_words[:8*unit]]\n",
        "  target_words_train_labels = pad_sequences(target_words_train_labels,padding='post')\n",
        "  target_words_train_labels = np.expand_dims(target_words_train_labels,axis=2)\n",
        "\n",
        "  target_words_dev_labels = pad_sequences([sent[1:] + [eos] for sent in target_words[8 * unit:9 * unit]], padding='post')\n",
        "  target_words_test_labels = pad_sequences([sent[1:] + [eos] for sent in target_words[9 * unit:]], padding='post')\n",
        "\n",
        "  train_data = [source_words_train,target_words_train,target_words_train_labels]\n",
        "  dev_data = [source_words_dev,target_words_dev_labels]\n",
        "  test_data = [source_words_test,target_words_test_labels]\n",
        "\n",
        "  return train_data,dev_data,test_data,source_lang_dict,target_lang_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqCZfhwi3h6E",
        "outputId": "c1acdd58-8677-4f13-b870-b41b0eaa5d2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "source_path = \"/drive/My Drive/CK Bigdata/Model 1/en.txt\"\n",
        "target_path = \"/drive/My Drive/CK Bigdata/Model 1/vi.txt\"\n",
        "\n",
        "train_data,dev_data,test_data,source_lang_dict,target_lang_dict = load_dataset(source_path,target_path, max_num_examples=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyslL_ax3h9N",
        "outputId": "54f1f7b2-bb65-45e4-dea4-4888b401db91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training set: 3\n",
            "source_words\n",
            "[2 3 4 5 6 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "['the', 'science', 'behind', 'a', 'climate', '<unk>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "target words\n",
            "[ 7  1  8  9  1  1  1  1  1  5  1 10  2  1 11 12  4  2  1  1 13  6 14  9\n",
            " 15 16 17 18 19 10 20 21  1 18 22  5  1 23 24  2  1  7  1 10 25 13  5 26\n",
            " 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "['một', '<unk>', 'tiêu', 'đề', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'đằng', '<unk>', 'về', '<start>', '<unk>', 'khí', 'hậu', 'học', '<start>', '<unk>', '<unk>', '<end>', 'sau', 'trong', 'đề', '4', 'phút', ',', 'chuyên', 'gia', 'về', 'hoá', 'quyển', '<unk>', 'chuyên', 'giới', 'đằng', '<unk>', 'thiệu', 'sơ', '<start>', '<unk>', 'một', '<unk>', 'về', 'lược', '<end>', 'đằng', 'những', 'nỗ', 'lực', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "target word labels\n",
            "['bạo', 'biến', 'đổi', 'cùng', 'với', 'cùng', 'đoàn', 'nghiên', 'cứu', '<start>', 'của', 'về', '<start>', 'khí', 'hậu', 'mình', '--', 'hàng', 'ngàn', '<start>', '<unk>', 'đoàn', 'người', 'một', '<start>', 'đã', 'lực', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shape of training set: {len(train_data)}\")\n",
        "\n",
        "print(\"source_words\")\n",
        "print(train_data[0][0])\n",
        "print([source_lang_dict.ids2word[word] for word in train_data[0][0]])\n",
        "print(\"target words\")\n",
        "print(train_data[0][1])\n",
        "print([target_lang_dict.ids2word[word] for word in train_data[0][1]])\n",
        "print(\"target word labels\")\n",
        "print([target_lang_dict.ids2word[word] for word in train_data[0][2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzcY9XQb3iAX",
        "outputId": "dc4870f4-373e-40e7-e01a-48f9549e2a1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 55,   1,  48, ...,   0,   0,   0],\n",
              "       [139, 246, 494, ...,   0,   0,   0],\n",
              "       [268,   9,  81, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [ 81,  82,   5, ...,   0,   0,   0],\n",
              "       [ 81, 204, 205, ...,   0,   0,   0],\n",
              "       [114, 204,  48, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXkTUK4D3iDM",
        "outputId": "a6402599-8a53-4654-8565-238072dd1e37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[  15, 1332,  263, ...,    0,    0,    0],\n",
              "        [  50,   44,   99, ...,    0,    0,    0],\n",
              "        [ 565,   46,   45, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 109,   82,    5, ...,    0,    0,    0],\n",
              "        [  50,   81,    1, ...,    0,    0,    0],\n",
              "        [   7,  130,    1, ...,    0,    0,    0]], dtype=int32),\n",
              " array([[ 33, 248, 393, ...,   0,   0,   0],\n",
              "        [ 88, 474, 291, ...,   0,   0,   0],\n",
              "        [474, 815,  10, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [ 82,   7, 342, ...,   0,   0,   0],\n",
              "        [ 88, 145, 380, ...,   0,   0,   0],\n",
              "        [ 14,   1, 139, ...,   0,   0,   0]], dtype=int32)]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-n7ElN83iGF"
      },
      "outputs": [],
      "source": [
        "class AttentionLayer(Layer):\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    if mask == None:\n",
        "      return None\n",
        "    return mask[1]\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return (input_shape[1][0],input_shape[1][1],input_shape[1][2]*2)\n",
        "\n",
        "\n",
        "  def call(self, inputs, mask=None):\n",
        "    encoder_outputs, decoder_outputs = inputs\n",
        "    \n",
        "    decoder_outputs_T =  K.permute_dimensions(decoder_outputs,(0,2,1))\n",
        "\n",
        "    luong_score = K.batch_dot(encoder_outputs,\n",
        "                        decoder_outputs_T,\n",
        "                        axes =[2,1]) \n",
        "\n",
        "    luong_score_softmax = K.softmax(luong_score, axis=1)\n",
        "\n",
        "    luong_score_softmax_expand = K.expand_dims(luong_score_softmax,-1) \n",
        "\n",
        "    encoder_outputs_expand = K.expand_dims(encoder_outputs,2)\n",
        "\n",
        "    product = encoder_outputs_expand*luong_score_softmax_expand\n",
        "\n",
        "    encoder_vector = K.sum(product,axis = 1)\n",
        "    \n",
        "    new_decoder_outputs = K.concatenate([decoder_outputs, encoder_vector])\n",
        "\n",
        "    return new_decoder_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exFLVW8E3iI-"
      },
      "outputs": [],
      "source": [
        "class NmtModel(object):\n",
        "  def __init__(self,source_dict,target_dict,use_attention):\n",
        "\n",
        "    self.hidden_size = 200\n",
        "    # the size of the word embeddings being used\n",
        "    self.embedding_size = 100\n",
        "    # the dropout rate for the hidden layers\n",
        "    self.hidden_dropout_rate=0.2\n",
        "    # the dropout rate for the word embeddings\n",
        "    self.embedding_dropout_rate = 0.2\n",
        "    # batch size\n",
        "    self.batch_size = 100\n",
        "\n",
        "    self.max_target_step = 30\n",
        "\n",
        "    # vocab size for source and target; we'll use everything we receive\n",
        "    self.vocab_target_size = len(target_dict.vocab)\n",
        "    self.vocab_source_size = len(source_dict.vocab)\n",
        "\n",
        "    # instances of the dictionaries\n",
        "    self.target_dict = target_dict\n",
        "    self.source_dict = source_dict\n",
        "\n",
        "    # special tokens to indicate sentence starts and ends.\n",
        "    self.SOS = target_dict.word2ids['<start>']\n",
        "    self.EOS = target_dict.word2ids['<end>']\n",
        "\n",
        "    # Boolean to use attention or not\n",
        "    # use attention or no\n",
        "    self.use_attention = use_attention\n",
        "\n",
        "    print(\"number of tokens in source: %d, number of tokens in target:%d\" % (self.vocab_source_size,self.vocab_target_size))\n",
        "\n",
        "\n",
        "\n",
        "  def build(self):\n",
        "\n",
        "    #-------------------------Train Models------------------------------\n",
        "    source_words = Input(shape=(None,),dtype='int32')\n",
        "    target_words = Input(shape=(None,), dtype='int32')\n",
        "\n",
        "    print('Task 1(a): Creating the embedding lookups...')\n",
        "    embeddings_source = Embedding(self.vocab_source_size, self.embedding_size, name='embedding_source', #Note the first argument here is the vocabulary size\n",
        "                        \tembeddings_initializer='glorot_uniform', mask_zero=True, trainable=True)\n",
        "    embeddings_target = Embedding(self.vocab_target_size, self.embedding_size, name='embedding_target', #Note the first argument here is the vocabulary size\n",
        "                        \tembeddings_initializer='glorot_uniform', mask_zero=True, trainable=True) \n",
        "    \n",
        "    # (b.) Look up the embeddings for source words and for target words. Apply dropout to each encoded input\n",
        "    print('\\nTask 1(b): Looking up source and target words...')\n",
        "    source_word_embeddings = embeddings_source(source_words)\n",
        "    target_words_embeddings = embeddings_target(target_words)\n",
        "\n",
        "    source_word_embeddings = Dropout(self.embedding_dropout_rate, \n",
        "                             input_shape = source_word_embeddings.shape, \n",
        "                             name = \"dropout_source_embedding\",seed=1010)(source_word_embeddings)\n",
        "\n",
        "    target_words_embeddings = Dropout(self.embedding_dropout_rate, \n",
        "                          input_shape = source_word_embeddings.shape, \n",
        "                          name = \"dropout_target_embedding\",seed=1010)(target_words_embeddings)\n",
        "\n",
        "\n",
        "\n",
        "    # (c.) An encoder LSTM() with return sequences set to True\n",
        "    print('\\nTask 1(c): Creating an encoder')\n",
        "    encoder_lstm = LSTM(self.hidden_size, return_sequences = True, return_state = True, name = \"encoder_LSTM\")\n",
        "\n",
        "    encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(source_word_embeddings)\n",
        "    \"\"\"\n",
        "    End Task 1\n",
        "    \"\"\"\n",
        "    encoder_states = [encoder_state_h,encoder_state_c]\n",
        "\n",
        "    # The train decoder\n",
        "    decoder_lstm = LSTM(self.hidden_size, recurrent_dropout=self.hidden_dropout_rate, \n",
        "                        return_sequences=True, return_state=True, name = \"decoder_LSTM\")\n",
        "    decoder_outputs_train,_,_ = decoder_lstm(target_words_embeddings,initial_state=encoder_states)\n",
        "\n",
        "    if self.use_attention:\n",
        "      decoder_attention = AttentionLayer()\n",
        "      decoder_outputs_train = decoder_attention([encoder_outputs,decoder_outputs_train])\n",
        "\n",
        "    decoder_dense = Dense(self.vocab_target_size,activation='softmax')\n",
        "    decoder_outputs_train = decoder_dense(decoder_outputs_train)\n",
        "\n",
        "    # compiling the train model.\n",
        "    adam = Adam(lr=0.01,clipnorm=5.0)\n",
        "    self.train_model = Model([source_words,target_words], decoder_outputs_train)\n",
        "    self.train_model.compile(optimizer=adam,loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # at this point you can print model summary for the train model\n",
        "    print('\\t\\t\\t\\t\\t\\t Train Model Summary.')\n",
        "    self.train_model.summary()\n",
        "\n",
        "    self.encoder_model = Model(source_words,[encoder_outputs,encoder_state_h,encoder_state_c])\n",
        "    # at this point you can print the summary for the encoder model.\n",
        "    print('\\t\\t\\t\\t\\t\\t Inference Time Encoder Model Summary.')\n",
        "    self.encoder_model.summary()\n",
        "\n",
        "    # The decoder model\n",
        "    # specifying the inputs to the decoder\n",
        "    decoder_state_input_h = Input(shape=(self.hidden_size,)) # last hidden State\n",
        "    decoder_state_input_c = Input(shape=(self.hidden_size,)) # cell state\n",
        "    encoder_outputs_input = Input(shape=(None,self.hidden_size,)) # encoder outputs\n",
        "\n",
        "    print('\\n Putting together the decoder states')\n",
        "    decoder_states = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    # use decoder states as input to the decoder lstm to get the decoder outputs, h, and c for test time inference\n",
        "    decoder_outputs_test,decoder_state_output_h, decoder_state_output_c = decoder_lstm(target_words_embeddings,\n",
        "                                                                                       initial_state = decoder_states)\n",
        "\n",
        "    # Task 2 (b.) Add attention if attention\n",
        "    if self.use_attention:\n",
        "      decoder_outputs_test = decoder_attention([encoder_outputs_input, \n",
        "                                                decoder_outputs_test])\n",
        "\n",
        "    decoder_outputs_test = decoder_dense(decoder_outputs_test)\n",
        "\n",
        "    self.decoder_model = Model([target_words,decoder_state_input_h,decoder_state_input_c,encoder_outputs_input],\n",
        "                               [decoder_outputs_test,decoder_state_output_h,decoder_state_output_c])\n",
        "    # you can now view the model summary\n",
        "    print('\\t\\t\\t\\t\\t\\t Decoder Inference Model summary')\n",
        "    print(self.decoder_model.summary())\n",
        "\n",
        "\n",
        "\n",
        "  def time_used(self, start_time):\n",
        "    curr_time = time.time()\n",
        "    used_time = curr_time-start_time\n",
        "    m = used_time // 60\n",
        "    s = used_time - 60 * m\n",
        "    return \"%d m %d s\" % (m, s)\n",
        "\n",
        "\n",
        "\n",
        "  def train(self,train_data,dev_data,test_data, epochs):\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "      print(\"Starting training epoch {}/{}\".format(epoch + 1, epochs))\n",
        "      epoch_time = time.time()\n",
        "      source_words_train, target_words_train, target_words_train_labels = train_data\n",
        "\n",
        "      self.train_model.fit([source_words_train,target_words_train],target_words_train_labels,batch_size=self.batch_size)\n",
        "\n",
        "      print(\"Time used for epoch {}: {}\".format(epoch + 1, self.time_used(epoch_time)))\n",
        "      dev_time = time.time()\n",
        "      print(\"Evaluating on dev set after epoch {}/{}:\".format(epoch + 1, epochs))\n",
        "      self.eval(dev_data)\n",
        "      print(\"Time used for evaluate on dev set: {}\".format(self.time_used(dev_time)))\n",
        "\n",
        "    print(\"Training finished!\")\n",
        "    print(\"Time used for training: {}\".format(self.time_used(start_time)))\n",
        "\n",
        "    print(\"Evaluating on test set:\")\n",
        "    test_time = time.time()\n",
        "    self.eval(test_data)\n",
        "    print(\"Time used for evaluate on test set: {}\".format(self.time_used(test_time)))\n",
        "\n",
        "\n",
        "\n",
        "  def get_target_sentences(self, sents,vocab,reference=False):\n",
        "    str_sents = []\n",
        "    num_sent, max_len = sents.shape\n",
        "    for i in range(num_sent):\n",
        "      str_sent = []\n",
        "      for j in range(max_len):\n",
        "        t = sents[i,j].item()\n",
        "        if t == self.SOS:\n",
        "          continue\n",
        "        if t == self.EOS:\n",
        "          break\n",
        "\n",
        "        str_sent.append(vocab[t])\n",
        "      if reference:\n",
        "        str_sents.append([str_sent])\n",
        "      else:\n",
        "        str_sents.append(str_sent)\n",
        "    return str_sents\n",
        "\n",
        "\n",
        "\n",
        "  def eval(self, dataset,print_outputs = False):\n",
        "    # get the source words and target_word_labels for the eval dataset\n",
        "    source_words, target_words_labels = dataset\n",
        "    vocab = self.target_dict.vocab\n",
        "\n",
        "    # using the same encoding network used during training time, encode the training\n",
        "    encoder_outputs, state_h,state_c = self.encoder_model.predict(source_words,batch_size=self.batch_size)\n",
        "    # for max_target_step steps, feed the step target words into the decoder.\n",
        "    predictions = []\n",
        "    step_target_words = np.ones([source_words.shape[0],1]) * self.SOS #start with <Start> symbol, initialized as a vector of <Start> symbols\n",
        "    for _ in range(self.max_target_step):\n",
        "      \n",
        "      step_decoder_outputs, state_h,state_c = self.decoder_model.predict([step_target_words,state_h,state_c,encoder_outputs],batch_size=self.batch_size)\n",
        "      step_target_words = np.argmax(step_decoder_outputs,axis=2)\n",
        "      predictions.append(step_target_words)\n",
        "\n",
        "    # predictions is a [time_step x batch_size x 1] array. We use get_target_sentence() to recover the batch_size sentences\n",
        "    candidates = self.get_target_sentences(np.concatenate(predictions,axis=1),vocab)\n",
        "    references = self.get_target_sentences(target_words_labels,vocab,reference=True)\n",
        "\n",
        "    # score using nltk bleu scorer\n",
        "    score = corpus_bleu(references,candidates)\n",
        "    print(\"Model BLEU score: %.2f\" % (score*100.0))\n",
        "\n",
        "    #Modification\n",
        "    if print_outputs:\n",
        "      sources = self.get_target_sentences(np.array(source_words[0:len(source_words)]),self.source_dict.vocab)\n",
        "      return sources,  candidates, references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p3DwtMr3iLd"
      },
      "outputs": [],
      "source": [
        "def print_examples(model, example_no = 10):\n",
        "\n",
        "  sources,  candidates, references = model.eval(test_data,print_outputs=True)\n",
        "\n",
        "  for i in range(example_no-1):\n",
        "\n",
        "    print(f\"example:{i+1}\")\n",
        "    print(f\"Source sentence: {' '.join(sources[i]).replace('<pad>', '')}\")\n",
        "    print(f\"Predicted translation: {' '.join(candidates[i]).replace('<pad>', '')}\")\n",
        "    print(f\"Actual translation: {' '.join([l[0] for l in references][i]).replace('<pad>', '')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxKUUT2K3iQd"
      },
      "outputs": [],
      "source": [
        "def main(source_path, target_path, use_attention):\n",
        "  max_example = 10000\n",
        "  print('loading dictionaries')\n",
        "  train_data, dev_data, test_data, source_dict, target_dict = load_dataset(source_path,target_path,max_num_examples=max_example)\n",
        "  print(\"read %d/%d/%d train/dev/test batches\" % (len(train_data[0]),len(dev_data[0]), len(test_data[0])))\n",
        "\n",
        "  model = NmtModel(source_dict,target_dict,use_attention)\n",
        "  model.build()\n",
        "  model.train(train_data,dev_data,test_data,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc9hEy8K3iTX",
        "outputId": "87829f1e-9aa3-4171-d93d-4025163510d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of tokens in source: 1514, number of tokens in target:1525\n",
            "Task 1(a): Creating the embedding lookups...\n",
            "\n",
            "Task 1(b): Looking up source and target words...\n",
            "\n",
            "Task 1(c): Creating an encoder\n",
            "\t\t\t\t\t\t Train Model Summary.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_source (Embedding)   (None, None, 100)    151400      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_target (Embedding)   (None, None, 100)    152500      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_source_embedding (Drop  (None, None, 100)   0           ['embedding_source[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_target_embedding (Drop  (None, None, 100)   0           ['embedding_target[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " encoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_source_embedding[0][0]'\n",
            "                                 (None, 200),                    ]                                \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " decoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_target_embedding[0][0]'\n",
            "                                 (None, 200),                    , 'encoder_LSTM[0][1]',          \n",
            "                                 (None, 200)]                     'encoder_LSTM[0][2]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 1525)   306525      ['decoder_LSTM[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,092,025\n",
            "Trainable params: 1,092,025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_source (Embedding  (None, None, 100)        151400    \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_source_embedding (D  (None, None, 100)        0         \n",
            " ropout)                                                         \n",
            "                                                                 \n",
            " encoder_LSTM (LSTM)         [(None, None, 200),       240800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 392,200\n",
            "Trainable params: 392,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            " Putting together the decoder states\n",
            "\t\t\t\t\t\t Decoder Inference Model summary\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_target (Embedding)   (None, None, 100)    152500      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_target_embedding (Drop  (None, None, 100)   0           ['embedding_target[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " decoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_target_embedding[0][0]'\n",
            "                                 (None, 200),                    , 'input_3[0][0]',               \n",
            "                                 (None, 200)]                     'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, None, 200)]  0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 1525)   306525      ['decoder_LSTM[1][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 699,825\n",
            "Trainable params: 699,825\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#Clear session prior to creating the architecture\n",
        "tf.keras.backend.clear_session()\n",
        "model = NmtModel(source_lang_dict, target_lang_dict,False)\n",
        "model.build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0WhWhk23iZV",
        "outputId": "58fae8d2-f345-45e2-95da-3d74ba0ab587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training epoch 1/20\n",
            "80/80 [==============================] - 595s 7s/step - loss: 0.4249 - accuracy: 0.1013\n",
            "Time used for epoch 1: 9 m 55 s\n",
            "Evaluating on dev set after epoch 1/20:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model BLEU score: 4.27\n",
            "Time used for evaluate on dev set: 0 m 16 s\n",
            "Starting training epoch 2/20\n",
            "80/80 [==============================] - 595s 7s/step - loss: 0.3646 - accuracy: 0.1798\n",
            "Time used for epoch 2: 10 m 21 s\n",
            "Evaluating on dev set after epoch 2/20:\n",
            "Model BLEU score: 0.55\n",
            "Time used for evaluate on dev set: 0 m 15 s\n",
            "Starting training epoch 3/20\n",
            "80/80 [==============================] - 578s 7s/step - loss: 0.3328 - accuracy: 0.2258\n",
            "Time used for epoch 3: 10 m 21 s\n",
            "Evaluating on dev set after epoch 3/20:\n",
            "Model BLEU score: 0.71\n",
            "Time used for evaluate on dev set: 0 m 17 s\n",
            "Starting training epoch 4/20\n",
            "80/80 [==============================] - 563s 7s/step - loss: 0.3149 - accuracy: 0.2473\n",
            "Time used for epoch 4: 10 m 21 s\n",
            "Evaluating on dev set after epoch 4/20:\n",
            "Model BLEU score: 1.18\n",
            "Time used for evaluate on dev set: 0 m 13 s\n",
            "Starting training epoch 5/20\n",
            "80/80 [==============================] - 556s 7s/step - loss: 0.3022 - accuracy: 0.2633\n",
            "Time used for epoch 5: 9 m 21 s\n",
            "Evaluating on dev set after epoch 5/20:\n",
            "Model BLEU score: 0.56\n",
            "Time used for evaluate on dev set: 0 m 17 s\n",
            "Starting training epoch 6/20\n",
            "80/80 [==============================] - 554s 7s/step - loss: 0.2930 - accuracy: 0.2766\n",
            "Time used for epoch 6: 9 m 13 s\n",
            "Evaluating on dev set after epoch 6/20:\n",
            "Model BLEU score: 1.33\n",
            "Time used for evaluate on dev set: 0 m 16 s\n",
            "Starting training epoch 7/20\n",
            "80/80 [==============================] - 549s 7s/step - loss: 0.2858 - accuracy: 0.2845\n",
            "Time used for epoch 7: 9 m 21 s\n",
            "Evaluating on dev set after epoch 7/20:\n",
            "Model BLEU score: 1.45\n",
            "Time used for evaluate on dev set: 0 m 13 s\n",
            "Starting training epoch 8/20\n",
            "80/80 [==============================] - 561s 7s/step - loss: 0.2799 - accuracy: 0.2932\n",
            "Time used for epoch 8: 9 m 21 s\n",
            "Evaluating on dev set after epoch 8/20:\n",
            "Model BLEU score: 1.79\n",
            "Time used for evaluate on dev set: 0 m 17 s\n",
            "Starting training epoch 9/20\n",
            "80/80 [==============================] - 562s 7s/step - loss: 0.2743 - accuracy: 0.3000\n",
            "Time used for epoch 9: 9 m 21 s\n",
            "Evaluating on dev set after epoch 9/20:\n"
          ]
        }
      ],
      "source": [
        "model.train(train_data,dev_data,test_data,20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5jy0iLp3icQ",
        "outputId": "b542405f-0dbe-4db0-de58-862ff7875b37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model BLEU score: 2.24\n",
            "example:1\n",
            "Source sentence: with green technology and with <unk> to <unk> poverty , and global <unk> , world can become like this .                                                                                                           \n",
            "Predicted translation: <unk> <unk> : <unk> <unk> : <unk> <unk> , <unk> <unk> , <unk> <unk> , <unk> <unk> , <unk> , <unk> .\n",
            "Actual translation: với công nghệ xanh và với các khoản đầu tư để xoá bỏ đói nghèo , và với sự quản lý toàn cầu hiệu quả , thế giới có thể trở thành như thế này .\n",
            "example:2\n",
            "Source sentence: and look at position of old west .                                                                                                                      \n",
            "Predicted translation: và dĩ nhiên , <unk> <unk> : <unk> .\n",
            "Actual translation: và hãy nhìn vào vị trí của phương tây của ngày xưa .\n",
            "example:3\n",
            "Source sentence: remember when this blue box was all alone , leading world , living its own life .                                                                                                              \n",
            "Predicted translation: một vài người có thể làm việc với những người khác , và chúng ta có thể làm được điều đó .\n",
            "Actual translation: hãy nhớ về lúc chiếc thùng xanh này đứng một mình , dẫn đầu thế giới , sống trong thế giới của chính mình .\n",
            "example:4\n",
            "Source sentence: this will not happen &#91; again &#93; .                                                                                                                        \n",
            "Predicted translation: nó là một người đàn ông này .\n",
            "Actual translation: điều này sẽ không thể lặp lại .\n",
            "example:5\n",
            "Source sentence: role of old west in new world is to become foundation of modern world -- nothing more , nothing less .                                                                                                      \n",
            "Predicted translation: những người khác , chúng ta có thể thấy được những người khác , và chúng ta có thể thấy được những người khác , và chúng ta có thể\n",
            "Actual translation: vai trò của phương tây ngày xưa trong thế giới này nay là trở thành &#91; một phần &#93; nền tảng của thế giới hiện đại -- không nhiều hơn , cũng không ít hơn .\n",
            "example:6\n",
            "Source sentence: but it &apos;s a very important role .                                                                                                                        \n",
            "Predicted translation: nhưng nó là một <unk> <unk> .\n",
            "Actual translation: nhưng đó là vai trò cốt yếu .\n",
            "example:7\n",
            "Source sentence: do it well and get used to it .                                                                                                                       \n",
            "Predicted translation: nó không phải là một người đàn ông , và nó không phải là một phần của chúng ta .\n",
            "Actual translation: hãy làm tốt việc của mình và làm quen với việc đó .\n",
            "example:8\n",
            "Source sentence: thank you very much .                                                                                                                           \n",
            "Predicted translation: xin cảm ơn rất nhiều .\n",
            "Actual translation: cám ơn rất nhiều .\n",
            "example:9\n",
            "Source sentence: <unk> <unk> : technology of storytelling                                                                                                                         \n",
            "Predicted translation: <unk> <unk> : <unk> <unk> <unk> .\n",
            "Actual translation: <unk> <unk> : công nghệ kể chuyện\n"
          ]
        }
      ],
      "source": [
        "print_examples(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T05RR76o3ifX",
        "outputId": "4f50282a-c7e6-42a5-d887-1d35cdd74269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of tokens in source: 1514, number of tokens in target:1525\n",
            "Task 1(a): Creating the embedding lookups...\n",
            "\n",
            "Task 1(b): Looking up source and target words...\n",
            "\n",
            "Task 1(c): Creating an encoder\n",
            "\t\t\t\t\t\t Train Model Summary.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_source (Embedding)   (None, None, 100)    151400      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dropout_source_embedding (Drop  (None, None, 100)   0           ['embedding_source[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_target (Embedding)   (None, None, 100)    152500      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " encoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_source_embedding[0][0]'\n",
            "                                 (None, 200),                    ]                                \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " dropout_target_embedding (Drop  (None, None, 100)   0           ['embedding_target[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " decoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_target_embedding[0][0]'\n",
            "                                 (None, 200),                    , 'encoder_LSTM[0][1]',          \n",
            "                                 (None, 200)]                     'encoder_LSTM[0][2]']           \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  (None, None, 400)   0           ['encoder_LSTM[0][0]',           \n",
            " r)                                                               'decoder_LSTM[0][0]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 1525)   611525      ['attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,397,025\n",
            "Trainable params: 1,397,025\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "\t\t\t\t\t\t Inference Time Encoder Model Summary.\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_source (Embedding  (None, None, 100)        151400    \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_source_embedding (D  (None, None, 100)        0         \n",
            " ropout)                                                         \n",
            "                                                                 \n",
            " encoder_LSTM (LSTM)         [(None, None, 200),       240800    \n",
            "                              (None, 200),                       \n",
            "                              (None, 200)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 392,200\n",
            "Trainable params: 392,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Putting together the decoder states\n",
            "\t\t\t\t\t\t Decoder Inference Model summary\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_target (Embedding)   (None, None, 100)    152500      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_target_embedding (Drop  (None, None, 100)   0           ['embedding_target[0][0]']       \n",
            " out)                                                                                             \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, None, 200)]  0           []                               \n",
            "                                                                                                  \n",
            " decoder_LSTM (LSTM)            [(None, None, 200),  240800      ['dropout_target_embedding[0][0]'\n",
            "                                 (None, 200),                    , 'input_3[0][0]',               \n",
            "                                 (None, 200)]                     'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  (None, None, 400)   0           ['input_5[0][0]',                \n",
            " r)                                                               'decoder_LSTM[1][0]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 1525)   611525      ['attention_layer[1][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,004,825\n",
            "Trainable params: 1,004,825\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#Clear session prior to creating the architecture\n",
        "tf.keras.backend.clear_session()\n",
        "model_attention = NmtModel(source_lang_dict, target_lang_dict,True)\n",
        "model_attention.build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AI_8ylh3iif",
        "outputId": "fe736276-7b77-4ff6-92dd-843ce3a3971d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training epoch 1/10\n"
          ]
        }
      ],
      "source": [
        "model_attention.train(train_data,dev_data,test_data,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs6Iwu003ilH"
      },
      "outputs": [],
      "source": [
        "print_examples(model_attention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH9utqFl3ioc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "51900396-Phan Trung Nhan-51900665-Lam Nhu Ngoc-So 14-Model1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}