{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "51900396-Phan Trung Nhan-51900665-Lam Nhu Ngọc-Model 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wh-m0eoBgju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d250922-2972-4fe1-e697-3f00ec10630c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import io\n",
        "import string\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78ngDseDBtL1"
      },
      "source": [
        "os.chdir(\"./drive/My Drive/CK Bigdata/pet-translate-master/dataset/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctwg1Cz0Bgj0"
      },
      "source": [
        "en_filename = \"train.en.txt\"\n",
        "vi_filename = \"train.vi.txt\"\n",
        "\n",
        "raw_en_lines = open(en_filename, encoding='utf-8').read().strip().split(\"\\n\")\n",
        "raw_vi_lines = open(vi_filename, encoding='utf-8').read().strip().split(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8YFiaD0Bgj2"
      },
      "source": [
        "exclude = list(string.punctuation) + list(string.digits)\n",
        "\n",
        "def preprocess(sentence):\n",
        "    sent = sentence.lower()\n",
        "    sent = sent.strip()\n",
        "    sent = re.sub(\"'\", \" \", sent)\n",
        "    sent = re.sub(\"\\s+\", \" \", sent)\n",
        "    sent = ''.join([char for char in sent if char not in exclude])\n",
        "    sent = \"<start> \" + sent + \" <end>\"\n",
        "    return sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns3dSIsdBgj4",
        "outputId": "95f5c384-37d9-4f88-9ca3-6c2d7e14461e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "en_lines = []\n",
        "vi_lines = []\n",
        "min_len, max_len = 10, 14\n",
        "\n",
        "for eline, vline in zip(raw_en_lines, raw_vi_lines):\n",
        "    eline = preprocess(eline)\n",
        "    vline = preprocess(vline)\n",
        "    if min_len < len(eline.split(\" \")) < max_len and min_len < len(vline.split(\" \")) < max_len:\n",
        "        en_lines.append(eline)\n",
        "        vi_lines.append(vline)\n",
        "        \n",
        "print(len(en_lines))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8__gLcNKBgj6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M155yoJ6Bgj-"
      },
      "source": [
        "class Language():\n",
        "    def __init__(self, lines):\n",
        "        self.lines = lines\n",
        "        self.word2id = {}\n",
        "        self.id2word = {}\n",
        "        self.vocab = set()\n",
        "        self.max_len = 0\n",
        "        self.min_len = 0\n",
        "        self.vocab_size = 0\n",
        "        self.init_language_params()\n",
        "\n",
        "    def init_language_params(self):\n",
        "        for line in self.lines:\n",
        "            self.vocab.update(line.split(\" \"))\n",
        "        self.word2id['<pad>'] = 0\n",
        "        for id, word in enumerate(self.vocab):\n",
        "            self.word2id[word] = id + 1\n",
        "        for word, id in self.word2id.items():\n",
        "            self.id2word[id] = word\n",
        "        self.max_len = max([len(line.split(\" \")) for line in self.lines])\n",
        "        self.min_len = min([len(line.split(\" \")) for line in self.lines])\n",
        "        self.vocab_size = len(self.vocab) + 1\n",
        "            \n",
        "    def sentence_to_vector(self, sent):\n",
        "        return np.array([self.word2id[word] for word in sent.split(\" \")])\n",
        "            \n",
        "    def vector_to_sentence(self, vector):\n",
        "        return \" \".join([self.id2word[id] for id in vector])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lytHfioABgkA",
        "outputId": "72994b41-4d21-4a00-9de9-550ddc2a4480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inp_lang = Language(en_lines)\n",
        "tar_lang = Language(vi_lines)\n",
        "print(inp_lang.max_len, inp_lang.min_len)\n",
        "print(tar_lang.max_len, tar_lang.min_len)\n",
        "\n",
        "inp_vector = [inp_lang.sentence_to_vector(line) for line in inp_lang.lines]\n",
        "tar_vector = [tar_lang.sentence_to_vector(line) for line in tar_lang.lines]\n",
        "\n",
        "inp_tensor = tf.keras.preprocessing.sequence.pad_sequences(inp_vector, inp_lang.max_len, padding='post')\n",
        "tar_tensor = tf.keras.preprocessing.sequence.pad_sequences(tar_vector, tar_lang.max_len, padding='post')\n",
        "print(inp_tensor.shape, tar_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 11\n",
            "13 11\n",
            "(6016, 13) (6016, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD0jgFQDBgkD",
        "outputId": "410d49c6-2e75-485a-84ab-12883b682069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(inp_tensor, tar_tensor, test_size=0.3)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = x_train.shape[0]\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "hidden_unit = 1024\n",
        "embedding_size = 256\n",
        "print(BUFFER_SIZE)\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcyz7jK0BgkG",
        "outputId": "2459b539-35aa-456d-ecb7-b9318143919f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tmp_x, tmp_y = next(iter(dataset))\n",
        "print(tmp_x.shape)\n",
        "print(tmp_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 13)\n",
            "(32, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SLKFFDRBgkI"
      },
      "source": [
        "class Encode(tf.keras.Model):\n",
        "    def __init__(self, embedding_size, vocab_size, hidden_units):\n",
        "        super(Encode, self).__init__()\n",
        "        self.Embedding = tf.keras.layers.Embedding(vocab_size,embedding_size)\n",
        "        self.GRU = tf.keras.layers.GRU(\n",
        "            hidden_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            recurrent_initializer='glorot_uniform')\n",
        "        self.hidden_units = hidden_units\n",
        "        \n",
        "    def call(self, x, hidden_state):\n",
        "        try:\n",
        "            x = self.Embedding(x)\n",
        "        except:\n",
        "            print(x, print(inp_lang.vocab_size))          \n",
        "        outputs, last_state = self.GRU(x, hidden_state)\n",
        "        return outputs, last_state\n",
        "    \n",
        "    def init_hidden_state(self, batch_size):\n",
        "        return tf.zeros([batch_size, self.hidden_units])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bv5RJy2BgkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adcc02a7-d8f0-428e-b2ac-3fe00b1095ca"
      },
      "source": [
        "encoder = Encode(embedding_size, inp_lang.vocab_size, hidden_unit)\n",
        "hidden_state = encoder.init_hidden_state(BATCH_SIZE)\n",
        "tmp_outputs, last_state = encoder(tmp_x, hidden_state)\n",
        "print(tmp_outputs.shape)\n",
        "print(last_state.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 13, 1024)\n",
            "(32, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BhTc-AMBgkN"
      },
      "source": [
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self, hidden_units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W_out_encode = tf.keras.layers.Dense(hidden_unit)\n",
        "        self.W_state = tf.keras.layers.Dense(hidden_unit)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, encode_outs, pre_state):\n",
        "        pre_state = tf.expand_dims(pre_state, axis=1)\n",
        "        pre_state = self.W_state(pre_state)\n",
        "        encode_outs = self.W_out_encode(encode_outs)\n",
        "        score = self.V(\n",
        "            tf.nn.tanh(\n",
        "                pre_state + encode_outs)\n",
        "        )\n",
        "        score = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = score*encode_outs\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, score\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTEV2cEdBgkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d1daa1-d13b-4d95-905b-15669e545608"
      },
      "source": [
        "attention = Attention(hidden_unit)\n",
        "context_vector, attention_weight = attention(tmp_outputs, last_state)\n",
        "print(context_vector.shape, attention_weight.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 1024) (32, 13, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9beRmrQBgkR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fca1ac3-6bfd-4827-97c9-ee450e95d4c6"
      },
      "source": [
        "class Decode(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_units):\n",
        "        super(Decode, self).__init__()\n",
        "        self.hidden_units = hidden_units\n",
        "        self.Embedding = tf.keras.layers.Embedding(vocab_size,embedding_size)\n",
        "        self.Attention = Attention(hidden_units)\n",
        "        self.GRU = tf.keras.layers.GRU(\n",
        "            hidden_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            recurrent_initializer='glorot_uniform'\n",
        "        )\n",
        "        self.Fc = tf.keras.layers.Dense(vocab_size)\n",
        "            \n",
        "    def call(self, x, encode_outs, pre_state):\n",
        "        x = tf.expand_dims(x, axis=1)\n",
        "        try:\n",
        "            x = self.Embedding(x)\n",
        "        except:\n",
        "            print(x, print(tar_lang.vocab_size))          \n",
        "        context_vector, attention_weight = self.Attention(encode_outs, pre_state)\n",
        "        context_vector = tf.expand_dims(context_vector, axis=1)\n",
        "        gru_inp = tf.concat([x, context_vector], axis=-1)\n",
        "        out_gru, state = self.GRU(gru_inp)\n",
        "        out_gru = tf.reshape(out_gru, (-1, out_gru.shape[2]))\n",
        "        return self.Fc(out_gru), state\n",
        "    \n",
        "    \n",
        "decode = Decode(tar_lang.vocab_size, embedding_size, hidden_unit)\n",
        "print(last_state.shape, tmp_outputs.shape, tmp_y[:, 0].shape)\n",
        "decode_out, state = decode(tmp_y[:, 0], tmp_outputs, last_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 1024) (32, 13, 1024) (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9NvIA7wmRGF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c17XofrSBgkT"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDeHi5MuBgkZ"
      },
      "source": [
        "EPOCHS = 50\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "encoder = Encode(embedding_size, vocab_size=inp_lang.vocab_size, hidden_units=hidden_unit)\n",
        "decoder = Decode(vocab_size=tar_lang.vocab_size, embedding_size=embedding_size, hidden_units=hidden_unit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD68uO8EBgkc",
        "outputId": "2871931a-928b-4299-9fcb-85810ba02df1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for batch_id, (x, y) in enumerate(dataset.take(N_BATCH)):\n",
        "        loss = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            first_state = encoder.init_hidden_state(batch_size=BATCH_SIZE)\n",
        "            encode_outs, last_state = encoder(x, first_state)\n",
        "            decode_state = last_state\n",
        "            decode_input = [tar_lang.word2id[\"<start>\"]]*BATCH_SIZE\n",
        "            \n",
        "            for i in range(1, y.shape[1]):\n",
        "                decode_out, decode_state = decoder(decode_input, encode_outs, decode_state)\n",
        "                loss += loss_function(y[:, i], decode_out)\n",
        "                decode_input = y[:, i]\n",
        "                \n",
        "            train_vars = encoder.trainable_variables + decoder.trainable_variables\n",
        "            grads = tape.gradient(loss, train_vars)\n",
        "            optimizer.apply_gradients(zip(grads, train_vars))\n",
        "        total_loss += loss\n",
        "    print(total_loss.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8320.274\n",
            "7247.522\n",
            "6657.011\n",
            "6095.486\n",
            "5534.8374\n",
            "4982.254\n",
            "4532.11\n",
            "4017.9297\n",
            "3557.948\n",
            "3173.6047\n",
            "2842.0027\n",
            "2560.5618\n",
            "2225.467\n",
            "1944.0653\n",
            "1756.5061\n",
            "1531.0287\n",
            "1314.6042\n",
            "1126.2614\n",
            "977.7957\n",
            "870.2354\n",
            "755.12695\n",
            "641.2595\n",
            "564.043\n",
            "497.95233\n",
            "428.9099\n",
            "375.7786\n",
            "335.45346\n",
            "314.78412\n",
            "280.1253\n",
            "251.35327\n",
            "218.20825\n",
            "205.34764\n",
            "189.33994\n",
            "179.93619\n",
            "179.80649\n",
            "188.20985\n",
            "204.65053\n",
            "228.60097\n",
            "205.4685\n",
            "168.55176\n",
            "144.91571\n",
            "122.4156\n",
            "107.89786\n",
            "100.55751\n",
            "123.088104\n",
            "159.07336\n",
            "152.77591\n",
            "134.92027\n",
            "131.08786\n",
            "150.4461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wvvPpoqH5fL",
        "outputId": "e014fa9e-0032-4a7e-ac7f-a72e3a7db602",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def translate(inputs):\n",
        "    print(inp_lang.vector_to_sentence(inputs[0].numpy()))\n",
        "    result = ''\n",
        "\n",
        "    hidden = encoder.init_hidden_state(batch_size=1)\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    print(enc_out.shape, dec_hidden.shape)\n",
        "    \n",
        "    dec_input = [tar_lang.word2id['<start>']]\n",
        "    for t in range(tar_lang.max_len):\n",
        "        predictions, dec_hidden = decoder(dec_input, enc_out, dec_hidden)\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += tar_lang.id2word[predicted_id] + ' '\n",
        "        dec_input = [predicted_id]\n",
        "    return result\n",
        "  \n",
        "for inp, tar in dataset.take(N_BATCH):\n",
        "    print(translate(inp[1:2,:]))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> and the reason is  it aposs been done  <end> <pad>\n",
            "(1, 13, 1024) (1, 1024)\n",
            "và lý do là  nó được thực hiện  <end> được thực \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pidg8lDi7nYe",
        "outputId": "b5589ac0-23dd-43f3-8ac2-b83af6e2ebd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DatasetV2.take of <BatchDataset element_spec=(TensorSpec(shape=(None, 13), dtype=tf.int32, name=None), TensorSpec(shape=(None, 13), dtype=tf.int32, name=None))>>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inp, tar in dataset.take(N_BATCH):\n",
        "    print(translate(inp[2:3:1]))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGPqPpAgQ0ge",
        "outputId": "9bb3e259-de34-46b7-cff1-74480de95e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> and a number of sopranos uploaded their parts  <end> <pad> <pad>\n",
            "(1, 13, 1024) (1, 1024)\n",
            "và một số nữ cao đã gửi đoạn của họ  <end> của \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inp, tar in dataset.take(N_BATCH):\n",
        "    print(translate(inp[3:4:1]))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2oZNDAZRJLJ",
        "outputId": "16f5b7e7-5412-4bb8-f206-ee088d28ebca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> i don apost have anything interesting to say  quot <end> <pad>\n",
            "(1, 13, 1024) (1, 1024)\n",
            "chẳng nhẽ chẳng có gì hay ho để nói cả  quot <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(translate(inp[30:31,:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nos7TXODRJS6",
        "outputId": "d9ebab6d-c5ea-4c56-8092-e2c886e5e2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> but the other thing they needed was speed  <end> <pad> <pad>\n",
            "(1, 13, 1024) (1, 1024)\n",
            "nhưng điều còn lại họ cần là tốc độ  <end> cần là \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inp, tar in dataset.take(N_BATCH):\n",
        "    print(translate(inp[22:23:1]))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyMkqzg28T6N",
        "outputId": "2e2948a9-eecc-49f5-8fce-2cb0f1f0e12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> it aposs no different than sending a text  <end> <pad> <pad>\n",
            "(1, 13, 1024) (1, 1024)\n",
            "nó không khác gì việc gửi một tin nhắn  <end> việc gửi \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVgYXske7-ud",
        "outputId": "f65c8185-5418-4147-910a-d77608f97978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 13), dtype=int32, numpy=\n",
              "array([[ 593, 2163, 1373, 5274,  863, 5112,  480,  560, 3599, 3129, 5139,\n",
              "           1,  328],\n",
              "       [ 593, 2163, 1373, 2503, 5112,    1, 5700, 5913, 3423, 4567,    1,\n",
              "         328,    0],\n",
              "       [ 593, 2163, 3491, 1234, 4023,  904, 1225, 1552,  345,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593,  234, 4697, 4070, 1365, 4328, 1287, 5322, 5544,    1, 5645,\n",
              "         328,    0],\n",
              "       [ 593, 2163, 3651, 1523, 5700, 3668, 1373,    1, 4988, 1840,    1,\n",
              "         328,    0],\n",
              "       [ 593, 5639, 3841, 5112, 3491, 2743, 4023, 3682, 3118, 4170,    1,\n",
              "         328,    0],\n",
              "       [ 593, 4950, 4718,    1,  586, 3841, 5877, 5424, 4596, 2486,    1,\n",
              "         328,    0],\n",
              "       [ 593, 4390, 3958,   49, 4224, 4023, 5401,    1, 4558, 1110, 4122,\n",
              "           1,  328],\n",
              "       [ 593, 5639, 1373, 1359, 5112, 1864, 2967, 3841, 1858,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593, 2607, 5877, 1531, 3491, 4078, 3599, 1552, 4975,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593, 2163,  234, 1920,    1, 2163,  234, 1523, 5700,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593, 1373, 4473, 1163, 3423, 5020,    1,  817, 4158,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593,  206, 3784, 3668, 2658,    1,  206, 3784, 3668, 2658,    1,\n",
              "         328,    0],\n",
              "       [ 593,  234, 4441,    1, 4652,  409, 1110,  478, 3841, 1999,    1,\n",
              "         328,    0],\n",
              "       [ 593, 1658, 1222, 4023, 4908, 3958, 2607, 1730, 5322, 5009,    1,\n",
              "        5645,  328],\n",
              "       [ 593, 3841, 5112, 5578, 4498, 3713, 4023, 1373, 5865,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593, 2607, 1365, 5322, 3323, 2195, 5322, 5174, 3599, 1145,    1,\n",
              "         328,    0],\n",
              "       [ 593, 2163, 2607, 1343,  407, 1893, 4616, 4687,    1, 5645,  328,\n",
              "           0,    0],\n",
              "       [ 593,  758,    1,  234,  798, 4070, 1365, 5322, 3712,  480,  900,\n",
              "           1,  328],\n",
              "       [ 593, 5649, 5913, 3682, 3716,    1, 5700, 5913, 2122,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593, 5700, 5913, 1373,  985, 1270, 4023, 2542, 1101,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593,  234, 5150, 2980, 2690,    1,  234, 5150, 2980, 1195,    1,\n",
              "         328,    0],\n",
              "       [ 593, 5700, 5913,  943, 4354,  760, 4246, 3491, 3324,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593, 2163, 4558, 2369,  943, 3471, 1479, 5700, 5246,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593, 2163,  234,  399, 4070, 5856, 1465, 2882, 5649,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593, 3841, 5112, 4848, 2961,    1, 3841, 5112, 4848, 2979,    1,\n",
              "         328,    0],\n",
              "       [ 593, 2163, 4390,  234, 4081, 3245, 1106, 2252, 3969,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593, 1281, 5913, 2851,  621, 5322, 1658, 5649, 4500, 2865,    1,\n",
              "         328,    0],\n",
              "       [ 593, 3923, 2146,  735, 1136, 5112, 3491, 4081, 4458, 2676,    1,\n",
              "         328,    0],\n",
              "       [ 593, 3361,    1,  478,    1, 5850, 4023, 1373, 4652, 3787, 5700,\n",
              "           1,  328],\n",
              "       [ 593,  586, 1373,  426,  776, 1248, 3377, 5246, 4838,    1,  328,\n",
              "           0,    0],\n",
              "       [ 593, 5700, 5913, 1730, 5322, 3525, 4344, 3000, 2082, 4635,    1,\n",
              "         328,    0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}